import numpy as np
import imageio
import json
from typing import Dict, Any

# 1. å¯¼å…¥é€šç”¨å·¥å…·
from utils_api import get_api_engine, get_unique_filename
from prompt.prompt_for_adv import (
    get_action_and_response_format,
    get_navigation_hints,
    get_physics_rules,
    get_task_and_reward,
)
from obs.parse_adv_obs import parse_adversary_obs

# 2. å¯¼å…¥ç¯å¢ƒ
try:
    from pettingzoo.mpe import simple_adversary_v3
except ImportError:
    raise ImportError("è¯·å®‰è£… pettingzoo: pip install pettingzoo[mpe]")

def get_header(env_name: str, agent_name: str, step: int, role: str) -> str:
    return (
        f"ENV: {env_name}\n"
        f"AGENT: {agent_name}\n"
        f"ROLE: {role.upper()}\n"
        f"STEP: {step}"
    )


def _format_current_obs(obs_struct: Dict[str, Any], num_good: int) -> str:
    """Format current observation data with role-specific highlights."""
    json_str = json.dumps(obs_struct)
    
    # Add obs semantics
    obs_semantics = (
        "OBSERVATION SEMANTICS:\n"
        f"- obs vectors are relative coordinates [dx, dy] and distances.\n"
        f"- landmarks: There are {num_good} landmarks. One is the Goal.\n"
    )
    if obs_struct['role'] == 'ADVERSARY':
        obs_semantics += "- good_agents: The Good Agents you need to watch/follow.\n\n"
    else:
        obs_semantics += (
            "- goal: The relative position of the REAL TARGET.\n"
            "- adversary: The enemy you must fool.\n"
            "- teammates: Your partner in crime.\n\n"
        )
    
    if obs_struct['role'] == 'GOOD_AGENT':
        goal_info = (
            f"- REAL TARGET (GOAL): {obs_struct['goal']['rel']} (Dist: {obs_struct['goal']['dist']})\n"
            f"  -> This is where the team needs to be.\n"
        )
        adv_info = (
            f"- ADVERSARY POS: {obs_struct['adversary']['rel']} (Dist: {obs_struct['adversary']['dist']})\n"
            f"  -> If Adversary dist to Goal is small, you are losing points!\n"
        )
        return (
            obs_semantics +
            "CURRENT OBS (Structured):\n"
            f"{json_str}\n"
            "--------------------------------------------------\n"
            "CRITICAL INFO:\n"
            f"{goal_info}"
            f"{adv_info}"
            "--------------------------------------------------\n"
        )
    else:
        return (
            obs_semantics +
            "CURRENT OBS (Structured):\n"
            f"{json_str}\n"
            "--------------------------------------------------\n"
            "CRITICAL INFO:\n"
            "- UNKNOWN GOAL: You must guess which landmark is the target.\n"
            "- HINT: Look at 'landmarks' and 'good_agents'. Are agents converging on Landmark 0 or 1?\n"
            "--------------------------------------------------\n"
        )


def user_prompt_adversary(agent: str, step: int, obs: Dict[str, Any], is_adversary: bool, num_good: int) -> str:
    """Assemble full prompt from modular components."""
    role_name = "ADVERSARY" if is_adversary else "GOOD_AGENT"
    
    parts = [
        get_header("MPE_Simple_Adversary_v3", agent, step, role_name),
        get_task_and_reward(is_adversary),
        get_physics_rules(),
        get_action_and_response_format(),
        get_navigation_hints(is_adversary),
        _format_current_obs(obs, num_good),
    ]
    return "\n\n".join(parts)


# ==============================================================================
# 2. ä¸»æµç¨‹
# ==============================================================================

def run_adversary_game(provider: str, output_name: str, **kwargs):
    """
    è¿è¡Œ Adversary æ¸¸æˆ
    
    Args:
        provider: æ¨¡å‹æä¾›å•† ('qwen', 'deepseek', 'gpt', 'ollama', 'transformers', etc.)
        output_name: è¾“å‡ºæ–‡ä»¶åå‰ç¼€
        **kwargs: ä¼ é€’ç»™ get_api_engine çš„é¢å¤–å‚æ•°ï¼ˆæ”¯æŒ seed å‚æ•°ï¼‰
    """
    # é…ç½®
    N_GOOD = 3         # å¥½äººæ•°é‡          
    MAX_STEPS = 30      # Adversary ç¯å¢ƒé€šå¸¸æ­¥æ•°è¾ƒçŸ­
    
    # åˆå§‹åŒ–
    seed = kwargs.pop('seed', None)
    llm_engine = get_api_engine(provider, **kwargs)
    print(f"Initializing Adversary Env (N={N_GOOD})...")
    # æ³¨æ„ï¼šrender_mode="rgb_array" ç”¨äºç”Ÿæˆè§†é¢‘
    env = simple_adversary_v3.parallel_env(N=N_GOOD, max_cycles=MAX_STEPS, continuous_actions=True, render_mode="rgb_array")
    
    observations, infos = env.reset(seed=seed) if seed is not None else env.reset()
    frames = []
    
    # å…¨å±€ç»Ÿè®¡
    game_log = []
    total_reward_good = 0.0
    total_reward_adv = 0.0

    for step in range(MAX_STEPS):
        print(f"\n{'='*20} STEP {step} {'='*20}")
        
        # 1. æ¸²æŸ“ç”»é¢
        frame = env.render()
        if frame is not None: frames.append(frame)
        
        actions = {}
        # æš‚å­˜æœ¬å›åˆæ¯ä¸ªæ™ºèƒ½ä½“çš„ä¿¡æ¯ï¼Œç­‰æ‹¿åˆ° reward å†æ‰“å°
        step_buffer = {} 

        # --- 2. å†³ç­–é˜¶æ®µ (Decision Phase) ---
        for agent_id in env.agents:
            obs_raw = observations[agent_id]
            is_adversary = "adversary" in agent_id
            
            # A. è§£æè§‚æµ‹ (Parsing)
            obs_struct = parse_adversary_obs(obs_raw, agent_id, N_GOOD)
            
            # B. ç»„è£…æç¤ºè¯ (Prompting)
            full_prompt = user_prompt_adversary(agent_id, step, obs_struct, is_adversary, N_GOOD)
            
            # C. è°ƒç”¨å¤§æ¨¡å‹ (Reasoning)
            system_role = "You are a Spy. Capture the target." if is_adversary else "You are a Secret Agent. Protect the target."
            
            # ä¸ºäº†é˜²æ­¢ç½‘ç»œæ³¢åŠ¨ï¼Œå¯ä»¥åŠ ä¸ªç®€å•çš„é‡è¯•æˆ–è€…å¼‚å¸¸æ•è·ï¼ˆåœ¨ get_api_engine é‡Œå·²å¤„ç†ï¼‰
            action_vec, raw_thought = llm_engine.generate_action(system_role, full_prompt)
            
            # D. åŠ¨ä½œåå¤„ç† (Action Clipping)
            action_vec = np.clip(action_vec, 0.0, 1.0)
            actions[agent_id] = action_vec
            
            # å­˜å…¥ Buffer
            step_buffer[agent_id] = {
                "role": "BAD" if is_adversary else "GOOD",
                "obs_text": _format_current_obs(obs_struct, N_GOOD),
                "thought": raw_thought,
                "action": action_vec,
                # å­˜åŸå§‹ç»“æ„æ–¹ä¾¿åç»­å­˜ JSON
                "obs_struct": obs_struct 
            }

        if not actions: 
            print("No actions generated. Ending episode.")
            break

        # --- 3. ç¯å¢ƒæ­¥è¿› (Physics Step) ---
        observations, rewards, terminations, truncations, infos = env.step(actions)
        
        # --- 4. ç»Ÿä¸€æ‰“å°æ—¥å¿— (Readable Log & Analysis) ---
        for agent_id, info in step_buffer.items():
            reward = rewards.get(agent_id, 0.0)
            role_tag = f"[{info['role']}] {agent_id}"
            
            # ç´¯åŠ ç»Ÿè®¡
            if info['role'] == "GOOD":
                # Good agents å…±äº«å¥–åŠ±ï¼Œä¸ºäº†ä¸ç®—é‡ï¼Œè¿™é‡ŒåªåŠ ä¸€æ¬¡ï¼Œæˆ–è€…é™¤ä»¥ N
                # ç®€å•èµ·è§ï¼Œæˆ‘ä»¬åœ¨å¤–é¢å•ç®—
                pass
            else:
                total_reward_adv += reward

            # å­˜å…¥ JSON log
            game_log.append({
                "step": step,
                "agent": agent_id,
                "role": info['role'],
                "obs": info['obs_struct'],
                "action": info['action'].tolist(),
                "thought": info['thought'],
                "reward": reward
            })
            
            # æ‰“å°æ§åˆ¶å°
            print(f"\nğŸ”· {role_tag} | Reward: {reward:.3f}")
            
            # 4.1 æ‰“å°æ¨¡å‹çœ‹åˆ°çš„å…³é”®ä¿¡æ¯ (Obs Highlight)
            print(f"   ğŸ‘€ Obs Highlight:")
            for line in info['obs_text'].split('\n'):
                # åªæ‰“å°åŒ…å«å…³é”®ä¿¡æ¯çš„è¡Œï¼Œä¿æŒæ•´æ´
                if any(k in line for k in ["TARGET", "ADVERSARY", "Direction", "role"]):
                    print(f"      {line.strip()}")
            
            # 4.2 æ‰“å°æ€è€ƒè¿‡ç¨‹ (Thought)
            # å¤„ç† DeepSeek çš„ <think> æ ‡ç­¾æˆ– JSON æ ¼å¼ï¼Œå–å‰ 150 å­—ç¬¦é¢„è§ˆ
            thought_preview = info['thought'][:150].replace('\n', ' ')
            print(f"   ğŸ§  Thought: {thought_preview}...") 
            
            # 4.3 æ‰“å°åŠ¨ä½œ (Action)
            act = info['action']
            act_str = f"[{act[0]:.1f}, L:{act[1]:.2f}, R:{act[2]:.2f}, D:{act[3]:.2f}, U:{act[4]:.2f}]"
            print(f"   ğŸ¬ Action: {act_str}")

        # ç»Ÿè®¡ Good Agent çš„æ€»åˆ† (å–å…¶ä¸­ä¸€ä¸ªå³å¯ï¼Œå› ä¸ºå…±äº«)
        # å‡è®¾ agent_0 æ˜¯å¥½äºº
        if 'agent_0' in rewards:
            total_reward_good += rewards['agent_0']

        if all(terminations.values()) or all(truncations.values()):
            print("\nGame Over (Terminated/Truncated).")
            break

    env.close()
    
    # Add final summary
    mean_reward = (total_reward_good + total_reward_adv) / 2.0
    game_log.append({
        "final_summary": True,
        "total_rewards": {"good": total_reward_good, "adversary": total_reward_adv},
        "mean_reward": float(mean_reward)
    })
    
    print(f"\n{'='*40}")
    print(f"ğŸ“Š EPISODE SUMMARY")
    print(f"   Total Good Reward: {total_reward_good:.2f}")
    print(f"   Total Adv Reward:  {total_reward_adv:.2f}")
    print(f"   Mean Reward: {mean_reward:.2f}")
    print(f"{'='*40}\n")

    # --- 5. ä¿å­˜ç»“æœ ---
    if frames:
        final_video = get_unique_filename(output_name + ".mp4")
        print(f"Saving video to {final_video} ...")
        # macro_block_size=1 ç”¨äºè§£å†³æŸäº›æ’­æ”¾å™¨çš„å°ºå¯¸å…¼å®¹é—®é¢˜
        imageio.mimsave(final_video, frames, fps=4, macro_block_size=1)
    
    final_log = get_unique_filename(output_name + ".json")
    print(f"Saving logs to {final_log} ...")
    with open(final_log, "w", encoding="utf-8") as f:
        json.dump(game_log, f, indent=4, ensure_ascii=False)

# ==============================================================================
# 3. è¿è¡Œå…¥å£
# ==============================================================================
if __name__ == "__main__":
    # ========== ç»Ÿä¸€æ¨¡å‹æ¥å£ ==========
    # è¿œç¨‹ API: 'deepseek', 'qwen', 'gpt', 'gemini'
    # æœ¬åœ°æ¨¡å‹: 'transformers', 'ollama', 'vllm'
    
    # æ–¹å¼ 1: ä½¿ç”¨é»˜è®¤é…ç½®
    PROVIDER = "qwen"
    
    # æ–¹å¼ 2: è‡ªå®šä¹‰ API Key (å¯é€‰)
    # PROVIDER = "deepseek"
    # run_adversary_game(PROVIDER, "adv_demo", api_key="your-key")
    
    # æ–¹å¼ 3: ä½¿ç”¨æœ¬åœ° Ollama æ¨¡å‹
    # PROVIDER = "ollama"
    # run_adversary_game(PROVIDER, "adv_demo", model_name="qwen2.5:7b")
    
    # æ–¹å¼ 4: ä½¿ç”¨ Transformers æœ¬åœ°æ¨¡å‹
    # PROVIDER = "transformers"
    # run_adversary_game(PROVIDER, "adv_demo", model_path="Qwen/Qwen2.5-7B-Instruct", device="cuda")

    N_EPISODES = 1
    print(f"Plan to run {N_EPISODES} episodes...")

    for i in range(N_EPISODES):
        print(f"\n\n" + "="*40)
        print(f"ğŸ¬ STARTING BATCH {i+1} / {N_EPISODES}")
        batch_name = f"adv_demo_run_{i+1}"
        try:
            run_adversary_game(PROVIDER, batch_name)
        except Exception as e:
            print(f"âŒ Error: {e}")
            continue