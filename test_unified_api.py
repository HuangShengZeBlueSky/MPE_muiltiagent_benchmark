#!/usr/bin/env python3
"""
æ¨¡å‹æ¥å£ç»Ÿä¸€æµ‹è¯•ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ get_api_engine ç»Ÿä¸€æ¥å£è°ƒç”¨ä¸åŒæ¨¡å‹
"""

from utils_api import get_api_engine
import numpy as np

def test_model(provider: str, **kwargs):
    """æµ‹è¯•æŒ‡å®šæ¨¡å‹çš„æ¥å£"""
    print("=" * 60)
    print(f"æµ‹è¯•æ¨¡å‹: {provider}")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–å¼•æ“
        
        engine = get_api_engine(provider, **kwargs)
        print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"  Provider: {engine.provider}")
        print(f"  Model: {engine.model_name}")
        
        
        # ç®€å•æ¨ç†æµ‹è¯•
        system_prompt = "You are a decision module for a game agent. Output only one-line JSON."
        user_prompt = '{"action": [0.0, 0.0, 0.5, 0.0, 0.0], "notes": "test"}\nGenerate a similar JSON with different action values.'
        
        print("\nå‘é€æ¨ç†è¯·æ±‚...")
        action_vec, response = engine.generate_action(
            system_prompt,
            user_prompt,
            temperature=0.7,
            max_tokens=200,
            max_retries=2
        )
        
        print(f"âœ“ æ¨ç†æˆåŠŸ")
        print(f"  Action: {action_vec}")
        print(f"  Response: {response[:100]}...")
        
        return True
        
    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    print("\nğŸš€ å¼€å§‹ç»Ÿä¸€æ¥å£æµ‹è¯•\n")
    
    # ========== æµ‹è¯•è¿œç¨‹ API ==========
    print("\nã€è¿œç¨‹ API æµ‹è¯•ã€‘\n")
    
    # 1. Qwen
    test_model("zaiwen")  # ä½¿ç”¨ .env ä¸­çš„ API Key
    
    # 2. DeepSeek (éœ€è¦æ›¿æ¢ API Key)
    # test_model("deepseek", api_key="your-key")
    
    # 3. GPT (éœ€è¦ API Key)
    # test_model("gpt", api_key="your-key", model_name="gpt-4o-mini")
    
    # ========== æµ‹è¯•æœ¬åœ°æ¨¡å‹ ==========
    print("\n\nã€æœ¬åœ°æ¨¡å‹æµ‹è¯•ã€‘\n")
    
    # 4. Ollama (éœ€è¦å…ˆå¯åŠ¨ Ollama æœåŠ¡)
    # test_model("ollama", model_name="qwen2.5:7b")
    
    # 5. Transformers (éœ€è¦å…ˆä¸‹è½½æ¨¡å‹)
    # test_model("transformers", model_path="Qwen/Qwen2.5-1.5B-Instruct", device="cpu")
    
    # 6. vLLM (éœ€è¦ GPU)
    # test_model("vllm", model_path="Qwen/Qwen2.5-7B-Instruct")
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
    
    print("\nğŸ“– ä½¿ç”¨è¯´æ˜:")
    print("1. è¿œç¨‹ API: ç›´æ¥ä½¿ç”¨ï¼Œåªéœ€æä¾› API Key")
    print("2. Ollama: éœ€è¦å…ˆè¿è¡Œ `ollama serve` å¯åŠ¨æœåŠ¡")
    print("3. Transformers: éœ€è¦å…ˆä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°")
    print("4. vLLM: éœ€è¦ GPU æ”¯æŒ")
    
    print("\nğŸ’¡ åˆ‡æ¢æ¨¡å‹ç¤ºä¾‹:")
    print('  engine = get_api_engine("qwen")  # è¿œç¨‹ API')
    print('  engine = get_api_engine("ollama", model_name="llama3.1:8b")  # æœ¬åœ°')
    print('  engine = get_api_engine("transformers", model_path="/path/to/model")  # è‡ªå®šä¹‰è·¯å¾„')
