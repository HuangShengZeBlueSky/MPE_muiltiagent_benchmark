#!/usr/bin/env python3
"""
å¿«é€Ÿå¼€å§‹ï¼šåˆ‡æ¢ä¸åŒæ¨¡å‹è¿è¡Œ Spread æ¸¸æˆ
"""

from spread_API import run_spread_game

# ============================================================
# æ–¹å¼ 1: è¿œç¨‹ API (æ¨èç”¨äºå¿«é€Ÿæµ‹è¯•)
# ============================================================

# Qwen (é˜¿é‡Œé€šä¹‰åƒé—®) - é»˜è®¤é…ç½®å·²åŒ…å« API Key
run_spread_game("qwen", "demo_qwen.mp4")

# DeepSeek - éœ€è¦æä¾›ä½ çš„ API Key
# run_spread_game("deepseek", "demo_deepseek.mp4", api_key="sk-your-key")

# GPT (OpenAI) - éœ€è¦æä¾›ä½ çš„ API Key
# run_spread_game("gpt", "demo_gpt.mp4", api_key="sk-your-key", model_name="gpt-4o")

# Gemini (Google) - éœ€è¦æä¾›ä½ çš„ API Key
# run_spread_game("gemini", "demo_gemini.mp4", api_key="your-key")


# ============================================================
# æ–¹å¼ 2: æœ¬åœ°æ¨¡å‹ - Ollama (æ¨èç”¨äºæœ¬åœ°å¼€å‘)
# ============================================================
# å‰æ: å…ˆå®‰è£…å¹¶å¯åŠ¨ Ollama
# 1. å®‰è£…: https://ollama.com
# 2. æ‹‰å–æ¨¡å‹: ollama pull qwen2.5:7b
# 3. è¿è¡Œ:

# run_spread_game("ollama", "demo_ollama.mp4", model_name="qwen2.5:7b")

# æˆ–ä½¿ç”¨å…¶ä»– Ollama æ¨¡å‹
# run_spread_game("ollama", "demo_llama.mp4", model_name="llama3.1:8b")


# ============================================================
# æ–¹å¼ 3: æœ¬åœ°æ¨¡å‹ - Transformers (å®Œå…¨ç¦»çº¿)
# ============================================================
# å‰æ: pip install transformers torch accelerate

# æ–¹å¼ 3.1: ä½¿ç”¨ Hugging Face Hub è‡ªåŠ¨ä¸‹è½½
# run_spread_game(
#     "transformers",
#     "demo_transformers.mp4",
#     model_path="Qwen/Qwen2.5-7B-Instruct",  # æˆ–å…¶ä»– HF æ¨¡å‹
#     device="cuda"  # æˆ– "cpu", "auto"
# )

# æ–¹å¼ 3.2: ä½¿ç”¨æœ¬åœ°å·²ä¸‹è½½çš„æ¨¡å‹
# run_spread_game(
#     "transformers",
#     "demo_transformers.mp4",
#     model_path="/path/to/local/model",
#     device="cuda"
# )

# æ–¹å¼ 3.3: ä½¿ç”¨ CPU (å†…å­˜è¾ƒå°çš„æ¨¡å‹)
# run_spread_game(
#     "transformers",
#     "demo_transformers.mp4",
#     model_path="Qwen/Qwen2.5-1.5B-Instruct",
#     device="cpu"
# )


# ============================================================
# æ–¹å¼ 4: æœ¬åœ°æ¨¡å‹ - vLLM (é«˜æ€§èƒ½æ‰¹é‡æ¨ç†)
# ============================================================
# å‰æ: pip install vllm (éœ€è¦ CUDA GPU)

# run_spread_game(
#     "vllm",
#     "demo_vllm.mp4",
#     model_path="meta-llama/Llama-3-8B",
#     tensor_parallel_size=2  # ä½¿ç”¨ 2 å¼  GPU
# )


# ============================================================
# è‡ªå®šä¹‰å‚æ•°
# ============================================================
# å¯ä»¥è°ƒæ•´æ¸¸æˆå‚æ•°
# run_spread_game(
#     "qwen",
#     "demo_custom.mp4",
#     N=4,  # 4 ä¸ªæ™ºèƒ½ä½“
#     local_ratio=0.3,  # è°ƒæ•´å¥–åŠ±æƒé‡
#     temperature=0.8,  # è°ƒæ•´æ¨¡å‹åˆ›é€ æ€§
#     max_tokens=2048  # è°ƒæ•´æœ€å¤§ç”Ÿæˆé•¿åº¦
# )


print("""
âœ… ç»Ÿä¸€æ¥å£å·²å°±ç»ªï¼

ğŸ“ å¿«é€Ÿåˆ‡æ¢æ¨¡å‹çš„æ–¹æ³•:

1. è¿œç¨‹ API (æœ€ç®€å•):
   run_spread_game("qwen", "output.mp4")

2. æœ¬åœ° Ollama (æœ¬åœ°å¼€å‘):
   run_spread_game("ollama", "output.mp4", model_name="qwen2.5:7b")

3. æœ¬åœ° Transformers (å®Œå…¨ç¦»çº¿):
   run_spread_game("transformers", "output.mp4", 
                   model_path="Qwen/Qwen2.5-7B-Instruct")

4. é«˜æ€§èƒ½ vLLM (å¤§è§„æ¨¡æ¨ç†):
   run_spread_game("vllm", "output.mp4", 
                   model_path="meta-llama/Llama-3-8B")

ğŸ“– æ›´å¤šè¯¦æƒ…è¯·æŸ¥çœ‹: MODEL_USAGE_GUIDE.md
""")
